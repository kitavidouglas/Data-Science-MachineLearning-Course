{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0775b88-60e5-4d45-898d-12d6f28abd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 10:51:35,823 - INFO - Starting the script\n",
      "2025-06-20 10:51:37,768 - INFO - Filters: Region - , Month - \n",
      "2025-06-20 10:51:43,560 - INFO - Retrieved 50 projects\n",
      "2025-06-20 10:53:12,442 - ERROR - Error processing project 128292: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n",
      "2025-06-20 10:53:38,991 - INFO - Total issue rows prepared: 368\n",
      "2025-06-20 10:53:39,019 - INFO - Data saved to 'project_data.csv'\n",
      "2025-06-20 10:53:39,044 - ERROR - An error occurred in the main function: BlockItemContainer.add_table() missing 1 required positional argument: 'width'\n",
      "2025-06-20 10:53:39,045 - ERROR - Exception details:\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_9515/4000105020.py\", line 290, in main\n",
      "    doc = create_word_report(table_data, headers, region_filter, month_filter)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_9515/4000105020.py\", line 109, in create_word_report\n",
      "    header_table = header.add_table(rows=1, cols=2)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: BlockItemContainer.add_table() missing 1 required positional argument: 'width'\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt, RGBColor\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.oxml import OxmlElement\n",
    "from docx.oxml.ns import qn\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# HighBond API configuration\n",
    "API_TOKEN = \"e6589a07a91e1604d711c78ef1b8c091fc7c09119f11d2c4aad948fc53942675\"\n",
    "BASE_URL = \"https://apis-eu.highbond.com/v1/orgs/48414\"\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/vnd.api+json\"\n",
    "}\n",
    "\n",
    "def get_all_projects():\n",
    "    url = f\"{BASE_URL}/projects\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['data']\n",
    "    else:\n",
    "        logger.error(f\"Failed to get projects: {response.status_code} - {response.text}\")\n",
    "        return []\n",
    "\n",
    "def get_project_issues(project_id):\n",
    "    url = f\"{BASE_URL}/projects/{project_id}/issues\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['data']\n",
    "    else:\n",
    "        logger.error(f\"Failed to get issues for project {project_id}: {response.status_code} - {response.text}\")\n",
    "        return []\n",
    "\n",
    "def clean_html(value):\n",
    "    if isinstance(value, (int, float)):\n",
    "        return str(value)\n",
    "    if not isinstance(value, str):\n",
    "        return str(value)\n",
    "\n",
    "    soup = BeautifulSoup(value, 'html.parser')\n",
    "\n",
    "    # Check if there is a <table> tag and if so, convert it to a Word table\n",
    "    if soup.find('table'):\n",
    "        return convert_html_table_to_word(soup.find('table'))\n",
    "    \n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.decompose()\n",
    "    for br in soup.find_all(\"br\"):\n",
    "        br.replace_with(\"\\n\")\n",
    "    text = soup.get_text()\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "    return text\n",
    "\n",
    "def convert_html_table_to_word(table_soup):\n",
    "    \"\"\"Converts an HTML table into a Word table.\"\"\"\n",
    "    table = []\n",
    "    rows = table_soup.find_all('tr')\n",
    "\n",
    "    for row in rows:\n",
    "        cells = row.find_all(['td', 'th'])\n",
    "        table.append([cell.get_text(strip=True) for cell in cells])\n",
    "    \n",
    "    word_table = \"\"\n",
    "    for row in table:\n",
    "        word_table += \"| \" + \" | \".join(row) + \" |\\n\"\n",
    "\n",
    "    return word_table\n",
    "\n",
    "def prompt_filters():\n",
    "    region_filter = input(\"Enter region filter (partial match allowed): \")\n",
    "    month_filter = input(\"Enter month filter (YYYY-MM): \")\n",
    "    return region_filter, month_filter\n",
    "\n",
    "def create_word_report(table_data, headers, region_filter, month_filter):\n",
    "    doc = Document()\n",
    "\n",
    "    # -------- Define your styles --------\n",
    "    normal_style = doc.styles['Normal']\n",
    "    normal_style.font.name = 'Calibri'\n",
    "    normal_style.font.size = Pt(11)\n",
    "\n",
    "    h1_style = doc.styles['Heading 1']\n",
    "    h1_style.font.name = 'Calibri'\n",
    "    h1_style.font.size = Pt(16)\n",
    "    h1_style.font.color.rgb = RGBColor.from_string('107AB8')\n",
    "\n",
    "    h2_style = doc.styles['Heading 2']\n",
    "    h2_style.font.name = 'Calibri'\n",
    "    h2_style.font.size = Pt(12)\n",
    "    h2_style.font.color.rgb = RGBColor.from_string('EF6149')\n",
    "\n",
    "    # -------- Cover Page (with logos) --------\n",
    "    # This remains in Section 1\n",
    "    header = doc.sections[0].header\n",
    "    header_table = header.add_table(rows=1, cols=2)\n",
    "    header_table.autofit = True\n",
    "    c0, c1 = header_table.rows[0].cells\n",
    "    try:\n",
    "        c0.paragraphs[0].add_run().add_picture('minigroup_logo.png', width=Inches(1.5))\n",
    "        p = c1.paragraphs[0]\n",
    "        p.alignment = WD_ALIGN_PARAGRAPH.RIGHT\n",
    "        p.add_run().add_picture('eleven_degrees_logo.png', width=Inches(1.5))\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Could not load logos: {e}\")\n",
    "\n",
    "    title = doc.add_paragraph()\n",
    "    title_run = title.add_run(\"Regional Issues Report\")\n",
    "    title_run.font.name = 'Calibri'\n",
    "    title_run.font.size = Pt(24)\n",
    "    title_run.font.bold = True\n",
    "    title_run.font.color.rgb = RGBColor.from_string('107AB8')\n",
    "    title.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "\n",
    "    doc.add_paragraph(f\"Mini Group / Eleven Degrees Consulting\", style='Normal').alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    doc.add_paragraph(f\"Date: {datetime.today().strftime('%Y-%m-%d')}\", style='Normal').alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    doc.add_page_break()\n",
    "\n",
    "    # -------- Table of Contents --------\n",
    "    toc = doc.add_paragraph()\n",
    "    fld_char_begin = OxmlElement('w:fldChar'); fld_char_begin.set(qn('w:fldCharType'), 'begin')\n",
    "    instr_text = OxmlElement('w:instrText'); instr_text.set(qn('xml:space'), 'preserve')\n",
    "    instr_text.text = 'TOC \\\\o \"1-3\" \\\\h \\\\z \\\\u'\n",
    "    fld_char_separate = OxmlElement('w:fldChar'); fld_char_separate.set(qn('w:fldCharType'), 'separate')\n",
    "    text = OxmlElement('w:t'); text.text = \"Right-click to update Table of Contents\"\n",
    "    fld_char_separate.append(text)\n",
    "    fld_char_end = OxmlElement('w:fldChar'); fld_char_end.set(qn('w:fldCharType'), 'end')\n",
    "    r = toc.runs[0]._r\n",
    "    r.append(fld_char_begin); r.append(instr_text); r.append(fld_char_separate); r.append(fld_char_end)\n",
    "\n",
    "    doc.add_page_break()\n",
    "\n",
    "    # -------- Loop through projects --------\n",
    "    current_project = None\n",
    "    first_project = True\n",
    "\n",
    "    for row in table_data:\n",
    "        project_id, project_name = row[0], row[1]\n",
    "        branch, region, start_date, status = row[2], row[3], row[4], row[5]\n",
    "        bm, om, sup = row[14], row[15], row[16]\n",
    "\n",
    "        # New section (and page) for each project except the very first\n",
    "        if not first_project:\n",
    "            section = doc.add_section(WD_SECTION.NEW_PAGE)\n",
    "            # inject header in this new section:\n",
    "            hdr = section.header\n",
    "            hdr_para = hdr.paragraphs[0] if hdr.paragraphs else hdr.add_paragraph()\n",
    "            hdr_para.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "            hdr_para.font.size = Pt(9)\n",
    "            hdr_para.font.name = 'Calibri'\n",
    "            hdr_para.text = (\n",
    "                f\"Branch: {branch}    |    Region: {region}    |    \"\n",
    "                f\"Start Date: {start_date}    |    Status: {status}    |    \"\n",
    "                f\"Branch Manager: {bm}    |    Operations Manager: {om}    |    Supervisor: {sup}\"\n",
    "            )\n",
    "        else:\n",
    "            # For the very first project, reuse Section 1 but still add a header with details:\n",
    "            hdr = doc.sections[0].header\n",
    "            hdr_para = hdr.add_paragraph()\n",
    "            hdr_para.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "            hdr_para.font.size = Pt(9)\n",
    "            hdr_para.font.name = 'Calibri'\n",
    "            hdr_para.text = (\n",
    "                f\"Branch: {branch}    |    Region: {region}    |    \"\n",
    "                f\"Start Date: {start_date}    |    Status: {status}    |    \"\n",
    "                f\"Branch Manager: {bm}    |    Operations Manager: {om}    |    Supervisor: {sup}\"\n",
    "            )\n",
    "            first_project = False\n",
    "\n",
    "        # Project heading\n",
    "        doc.add_heading(f\"Project: {project_name}\", level=1)\n",
    "\n",
    "        # Loop through issues for this row\n",
    "        doc.add_heading(f\"Issue: {row[6]}\", level=2)\n",
    "        tbl = doc.add_table(rows=0, cols=2)\n",
    "        tbl.style = 'Light List Accent 1'\n",
    "        def add_row(label, value):\n",
    "            cells = tbl.add_row().cells\n",
    "            cells[0].text = label\n",
    "            cells[1].text = clean_html(value)\n",
    "\n",
    "        add_row(\"Severity\", row[7])\n",
    "        add_row(\"Description\", row[8])\n",
    "        add_row(\"Implication\", row[9])\n",
    "        add_row(\"Cost Impact\", f\"${row[10]}\")\n",
    "        add_row(\"Management Comment 1\", row[11])\n",
    "        add_row(\"Management Comment 2\", row[12])\n",
    "        add_row(\"Recommendation\", row[13])\n",
    "\n",
    "        doc.add_paragraph()\n",
    "\n",
    "    return doc\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        logger.info(\"Starting the script\")\n",
    "        region_filter, month_filter = prompt_filters()\n",
    "        logger.info(f\"Filters: Region - {region_filter}, Month - {month_filter}\")\n",
    "\n",
    "        projects = get_all_projects()\n",
    "        logger.info(f\"Retrieved {len(projects)} projects\")\n",
    "\n",
    "        table_data = []\n",
    "        headers = [\n",
    "            \"Project ID\", \"Project Name\", \"Branch\", \"Region\", \"Start Date\", \"Status\",\n",
    "            \"Issue Title\", \"Severity\", \"Description\", \"Implication\", \"Cost Impact\",\n",
    "            \"Management Comments 1\", \"Management Comments 2\", \"Recommendation\",\n",
    "            \"Branch Manager\", \"Operations Manager\", \"Supervisor\"\n",
    "        ]\n",
    "\n",
    "        for project in projects:\n",
    "            try:\n",
    "                project_id = project.get(\"id\")\n",
    "                if not project_id:\n",
    "                    logger.warning(f\"Project ID not found: {project}\")\n",
    "                    continue\n",
    "\n",
    "                project_attributes = project.get(\"attributes\", {})\n",
    "                project_name = project_attributes.get(\"name\", \"N/A\")\n",
    "                start_date = project_attributes.get(\"start_date\", \"\")\n",
    "                status = project_attributes.get(\"status\", \"N/A\")\n",
    "                project_custom_fields = project_attributes.get(\"custom_attributes\", [])\n",
    "\n",
    "                region = next((f.get(\"value\", \"N/A\") for f in project_custom_fields if f.get(\"term\") == \"Custom field 2\"), \"N/A\")\n",
    "                branch = next((f.get(\"value\", \"N/A\") for f in project_custom_fields if f.get(\"term\") == \"Custom field 8\"), \"N/A\")\n",
    "                branch_manager = next((f.get(\"value\", \"N/A\") for f in project_custom_fields if f.get(\"term\") == \"Custom field 5\"), \"N/A\")\n",
    "                operations_manager = next((f.get(\"value\", \"N/A\") for f in project_custom_fields if f.get(\"term\") == \"Custom field 6\"), \"N/A\")\n",
    "                supervisor = next((f.get(\"value\", \"N/A\") for f in project_custom_fields if f.get(\"term\") == \"Custom field 7\"), \"N/A\")\n",
    "\n",
    "                if region_filter and region_filter.lower() not in region.lower():\n",
    "                    logger.info(f\"Skipping project {project_name} due to region filter\")\n",
    "                    continue\n",
    "                if month_filter and not start_date.startswith(month_filter):\n",
    "                    logger.info(f\"Skipping project {project_name} due to month filter\")\n",
    "                    continue\n",
    "\n",
    "                issues = get_project_issues(project_id)\n",
    "                if len(issues) == 0:\n",
    "                    continue\n",
    "\n",
    "                for issue in issues:\n",
    "                    try:\n",
    "                        attributes = issue.get(\"attributes\", {})\n",
    "                        title = attributes.get(\"title\", \"\")\n",
    "                        severity = attributes.get(\"severity\", \"\")\n",
    "                        description = clean_html(attributes.get(\"description\", \"\"))\n",
    "                        implication = clean_html(attributes.get(\"effect\", \"\"))\n",
    "                        cost_impact = str(attributes.get(\"cost_impact\", 0))\n",
    "                        recommendation = clean_html(attributes.get(\"recommendation\", \"\"))\n",
    "\n",
    "                        issue_custom_attributes = attributes.get(\"custom_attributes\", [])\n",
    "                        mgmt_comment_1 = next((field.get(\"value\", \"\") for field in issue_custom_attributes if field.get(\"term\") == \"Custom field 1\"), \"\")\n",
    "                        mgmt_comment_2 = next((field.get(\"value\", \"\") for field in issue_custom_attributes if field.get(\"term\") == \"Custom field 2\"), \"\")\n",
    "\n",
    "                        row = [\n",
    "                            project_id, project_name, branch, region, start_date, status,\n",
    "                            title, severity, description, implication, cost_impact,\n",
    "                            mgmt_comment_1, mgmt_comment_2, recommendation,\n",
    "                            branch_manager, operations_manager, supervisor\n",
    "                        ]\n",
    "                        table_data.append(row)\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Error processing issue for project {project_name}: {str(e)}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing project {project.get('id', 'Unknown')}: {str(e)}\")\n",
    "\n",
    "        logger.info(f\"Total issue rows prepared: {len(table_data)}\")\n",
    "\n",
    "        if len(table_data) == 0:\n",
    "            logger.warning(\"No matching issues found\")\n",
    "        else:\n",
    "            df = pd.DataFrame(table_data, columns=headers)\n",
    "            df.to_csv(\"project_data.csv\", index=False)\n",
    "            logger.info(\"Data saved to 'project_data.csv'\")\n",
    "\n",
    "            doc = create_word_report(table_data, headers, region_filter, month_filter)\n",
    "            doc.save(\"project_report.docx\",)\n",
    "            logger.info(\"Report generated and saved as 'project_report.docx'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred in the main function: {str(e)}\")\n",
    "        logger.exception(\"Exception details:\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66077b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in /home/kitavidouglas/anaconda3/lib/python3.12/site-packages (1.1.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /home/kitavidouglas/anaconda3/lib/python3.12/site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /home/kitavidouglas/anaconda3/lib/python3.12/site-packages (from python-docx) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb5dcbc2-0a76-4504-be4a-08319190350d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 11:36:52,578 - INFO - Starting script\n",
      "2025-06-16 11:37:21,917 - WARNING - No matching issues found\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt, RGBColor\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.enum.section import WD_ORIENT\n",
    "from docx.oxml import OxmlElement\n",
    "from docx.oxml.ns import qn\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# HighBond API configuration\n",
    "API_TOKEN = \"e6589a07a91e1604d711c78ef1b8c091fc7c09119f11d2c4aad948fc53942675\"\n",
    "BASE_URL = \"https://apis-eu.highbond.com/v1/orgs/48414\"\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/vnd.api+json\"\n",
    "}\n",
    "\n",
    "def get_all_projects():\n",
    "    url = f\"{BASE_URL}/projects\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['data']\n",
    "    else:\n",
    "        logger.error(f\"Failed to get projects: {response.status_code} - {response.text}\")\n",
    "        return []\n",
    "\n",
    "def get_project_issues(project_id):\n",
    "    url = f\"{BASE_URL}/projects/{project_id}/issues\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['data']\n",
    "    else:\n",
    "        logger.error(f\"Failed to get issues for project {project_id}: {response.status_code} - {response.text}\")\n",
    "        return []\n",
    "\n",
    "def clean_html(value):\n",
    "    if isinstance(value, (int, float)):\n",
    "        return str(value)\n",
    "    if not isinstance(value, str):\n",
    "        return str(value)\n",
    "    soup = BeautifulSoup(value, 'html.parser')\n",
    "    if soup.find('table'):\n",
    "        return convert_html_table_to_word(soup.find('table'))\n",
    "    for tag in soup([\"script\", \"style\"]): tag.decompose()\n",
    "    for br in soup.find_all(\"br\"): br.replace_with(\"\\n\")\n",
    "    text = soup.get_text()\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    return '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "\n",
    "def convert_html_table_to_word(table_soup):\n",
    "    table = []\n",
    "    for row in table_soup.find_all('tr'):\n",
    "        cells = row.find_all(['td', 'th'])\n",
    "        table.append([cell.get_text(strip=True) for cell in cells])\n",
    "    word_table = \"\"\n",
    "    for row in table:\n",
    "        word_table += \"| \" + \" | \".join(row) + \" |\\n\"\n",
    "    return word_table\n",
    "\n",
    "def prompt_filters():\n",
    "    region_filter = input(\"Enter region filter (partial match allowed): \")\n",
    "    month_filter = input(\"Enter month filter (YYYY-MM): \")\n",
    "    return region_filter, month_filter\n",
    "\n",
    "def add_background_footer(section):\n",
    "    footer = section.footer\n",
    "    paragraph = footer.paragraphs[0]\n",
    "    run = paragraph.add_run()\n",
    "    run.text = \" \" * 200  # force footer area height\n",
    "    shading_elm = OxmlElement('w:shd')\n",
    "    shading_elm.set(qn('w:fill'), '107AB8')  # background color\n",
    "    shading_elm.set(qn('w:val'), 'clear')\n",
    "    run._r.get_or_add_rPr().append(shading_elm)\n",
    "\n",
    "def create_word_report(table_data, headers, region_filter, month_filter):\n",
    "    doc = Document()\n",
    "\n",
    "    # Set landscape orientation and margins\n",
    "    section = doc.sections[0]\n",
    "    section.orientation = WD_ORIENT.LANDSCAPE\n",
    "    section.page_width, section.page_height = Inches(11), Inches(8.5)\n",
    "    for s in doc.sections:\n",
    "        s.top_margin = s.bottom_margin = Inches(0.5)\n",
    "        s.left_margin = s.right_margin = Inches(0.5)\n",
    "\n",
    "    # Define styles\n",
    "    styles = doc.styles\n",
    "    styles['Normal'].font.name = 'Calibri'\n",
    "    styles['Normal'].font.size = Pt(11)\n",
    "\n",
    "    styles['Heading 1'].font.size = Pt(16)\n",
    "    styles['Heading 1'].font.color.rgb = RGBColor.from_string('107AB8')\n",
    "\n",
    "    styles['Heading 2'].font.size = Pt(13)\n",
    "    styles['Heading 2'].font.color.rgb = RGBColor.from_string('EF6149')\n",
    "\n",
    "    # Cover Page\n",
    "    doc.add_paragraph().add_run(\"Regional Issues Report\").bold = True\n",
    "    doc.paragraphs[-1].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    doc.paragraphs[-1].runs[0].font.size = Pt(24)\n",
    "    doc.paragraphs[-1].runs[0].font.color.rgb = RGBColor.from_string('107AB8')\n",
    "\n",
    "    subtitle = doc.add_paragraph(\"Mini Group / Eleven Degrees Consulting\")\n",
    "    subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    subtitle.runs[0].font.size = Pt(14)\n",
    "\n",
    "    doc.add_paragraph(f\"Date: {datetime.today().strftime('%Y-%m-%d')}\").alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    add_background_footer(doc.sections[0])\n",
    "    doc.add_page_break()\n",
    "\n",
    "    # Table of Contents\n",
    "    toc = doc.add_paragraph()\n",
    "    run = toc.add_run()\n",
    "    fldChar = OxmlElement('w:fldChar'); fldChar.set(qn('w:fldCharType'), 'begin')\n",
    "    instrText = OxmlElement('w:instrText'); instrText.text = 'TOC \\\\o \"1-2\" \\\\h \\\\z \\\\u'\n",
    "    fldChar2 = OxmlElement('w:fldChar'); fldChar2.set(qn('w:fldCharType'), 'separate')\n",
    "    fldChar3 = OxmlElement('w:fldChar'); fldChar3.set(qn('w:fldCharType'), 'end')\n",
    "    r_element = run._r\n",
    "    r_element.append(fldChar)\n",
    "    r_element.append(instrText)\n",
    "    r_element.append(fldChar2)\n",
    "    r_element.append(fldChar3)\n",
    "    doc.add_page_break()\n",
    "\n",
    "    # Group data by project\n",
    "    from collections import defaultdict\n",
    "    grouped_data = defaultdict(list)\n",
    "    for row in table_data:\n",
    "        if row[7].lower() in ['high', 'medium']:\n",
    "            grouped_data[row[0]].append(row)\n",
    "\n",
    "    for pid, rows in grouped_data.items():\n",
    "        project_name = rows[0][1]\n",
    "        branch, region, start_date, status = rows[0][2], rows[0][3], rows[0][4], rows[0][5]\n",
    "        bm, om, sup = rows[0][14], rows[0][15], rows[0][16]\n",
    "\n",
    "        # -- Page Header per project --\n",
    "        section = doc.add_section(start_type=1)\n",
    "        header = section.header\n",
    "        header_table = header.add_table(rows=2, cols=3, width=Inches(9))\n",
    "        header_table.autofit = True\n",
    "        header_table.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "\n",
    "        try:\n",
    "            header_table.cell(0, 0).paragraphs[0].add_run().add_picture(\"minigroup_logo.png\", width=Inches(1.2))\n",
    "            header_table.cell(0, 2).paragraphs[0].add_run().add_picture(\"eleven_degrees.jpg\", width=Inches(1.2))\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Header logo loading failed: {e}\")\n",
    "\n",
    "        header_text = header_table.cell(1, 1).paragraphs[0]\n",
    "        header_text.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        run = header_text.add_run(f\"Branch: {branch} | Region: {region} | Start: {start_date} | Status: {status}\\n\"\n",
    "                                  f\"BM: {bm} | OM: {om} | Sup: {sup}\")\n",
    "        run.font.size = Pt(9)\n",
    "\n",
    "        doc.add_heading(f\"Project: {project_name}\", level=1)\n",
    "\n",
    "        for row in rows:\n",
    "            doc.add_heading(f\"Issue: {row[6]}\", level=2)\n",
    "            table = doc.add_table(rows=0, cols=2)\n",
    "            table.style = 'Light List Accent 1'\n",
    "\n",
    "            def add_row(label, value):\n",
    "                row_cells = table.add_row().cells\n",
    "                row_cells[0].text = label\n",
    "                row_cells[1].text = clean_html(value)\n",
    "\n",
    "            add_row(\"Severity\", row[7])\n",
    "            add_row(\"Description\", row[8])\n",
    "            add_row(\"Implication\", row[9])\n",
    "            add_row(\"Cost Impact\", f\"${row[10]}\")\n",
    "            add_row(\"Management Comment 1\", row[11])\n",
    "            add_row(\"Management Comment 2\", row[12])\n",
    "            add_row(\"Recommendation\", row[13])\n",
    "            doc.add_paragraph()\n",
    "\n",
    "    # Custom Footer with Styled Page Numbers\n",
    "    for section in doc.sections:\n",
    "        footer = section.footer\n",
    "        para = footer.paragraphs[0]\n",
    "        para.alignment = WD_ALIGN_PARAGRAPH.RIGHT\n",
    "        run = para.add_run()\n",
    "        fldChar = OxmlElement('w:fldChar'); fldChar.set(qn('w:fldCharType'), 'begin')\n",
    "        instrText = OxmlElement('w:instrText'); instrText.text = 'PAGE'\n",
    "        fldChar2 = OxmlElement('w:fldChar'); fldChar2.set(qn('w:fldCharType'), 'separate')\n",
    "        fldChar3 = OxmlElement('w:fldChar'); fldChar3.set(qn('w:fldCharType'), 'end')\n",
    "        r_element = run._r\n",
    "        r_element.append(fldChar)\n",
    "        r_element.append(instrText)\n",
    "        r_element.append(fldChar2)\n",
    "        r_element.append(fldChar3)\n",
    "        run.font.size = Pt(9)\n",
    "        run.font.color.rgb = RGBColor.from_string('808080')\n",
    "\n",
    "    return doc\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        logger.info(\"Starting script\")\n",
    "        region_filter, month_filter = prompt_filters()\n",
    "        projects = get_all_projects()\n",
    "        table_data = []\n",
    "        headers = [\n",
    "            \"Project ID\", \"Project Name\", \"Branch\", \"Region\", \"Start Date\", \"Status\",\n",
    "            \"Issue Title\", \"Severity\", \"Description\", \"Implication\", \"Cost Impact\",\n",
    "            \"Management Comments 1\", \"Management Comments 2\", \"Recommendation\",\n",
    "            \"Branch Manager\", \"Operations Manager\", \"Supervisor\"\n",
    "        ]\n",
    "\n",
    "        for project in projects:\n",
    "            try:\n",
    "                pid = project.get(\"id\")\n",
    "                if not pid:\n",
    "                    continue\n",
    "                attr = project.get(\"attributes\", {})\n",
    "                name = attr.get(\"name\", \"N/A\")\n",
    "                start = attr.get(\"start_date\", \"\")\n",
    "                status = attr.get(\"status\", \"N/A\")\n",
    "                custom = attr.get(\"custom_attributes\", [])\n",
    "\n",
    "                region = next((f.get(\"value\", \"N/A\") for f in custom if f.get(\"term\") == \"Custom field 2\"), \"N/A\")\n",
    "                branch = next((f.get(\"value\", \"N/A\") for f in custom if f.get(\"term\") == \"Custom field 8\"), \"N/A\")\n",
    "                bm = next((f.get(\"value\", \"N/A\") for f in custom if f.get(\"term\") == \"Custom field 5\"), \"N/A\")\n",
    "                om = next((f.get(\"value\", \"N/A\") for f in custom if f.get(\"term\") == \"Custom field 6\"), \"N/A\")\n",
    "                sup = next((f.get(\"value\", \"N/A\") for f in custom if f.get(\"term\") == \"Custom field 7\"), \"N/A\")\n",
    "\n",
    "                if region_filter and region_filter.lower() not in region.lower(): continue\n",
    "                if month_filter and not start.startswith(month_filter): continue\n",
    "\n",
    "                issues = get_project_issues(pid)\n",
    "                if not issues: continue\n",
    "\n",
    "                for issue in issues:\n",
    "                    severity = issue[\"attributes\"].get(\"severity\", \"\").lower()\n",
    "                    if severity not in [\"high\", \"medium\"]:\n",
    "                        continue\n",
    "                    i_attr = issue.get(\"attributes\", {})\n",
    "                    title = i_attr.get(\"title\", \"\")\n",
    "                    desc = clean_html(i_attr.get(\"description\", \"\"))\n",
    "                    effect = clean_html(i_attr.get(\"effect\", \"\"))\n",
    "                    cost = str(i_attr.get(\"cost_impact\", 0))\n",
    "                    rec = clean_html(i_attr.get(\"recommendation\", \"\"))\n",
    "                    icustom = i_attr.get(\"custom_attributes\", [])\n",
    "                    cm1 = next((f.get(\"value\", \"\") for f in icustom if f.get(\"term\") == \"Custom field 1\"), \"\")\n",
    "                    cm2 = next((f.get(\"value\", \"\") for f in icustom if f.get(\"term\") == \"Custom field 2\"), \"\")\n",
    "\n",
    "                    row = [pid, name, branch, region, start, status, title, severity, desc, effect, cost, cm1, cm2, rec, bm, om, sup]\n",
    "                    table_data.append(row)\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing project {project.get('id')}: {e}\")\n",
    "\n",
    "        if table_data:\n",
    "            df = pd.DataFrame(table_data, columns=headers)\n",
    "            df.to_csv(\"project_data.csv\", index=False)\n",
    "            logger.info(\"CSV saved\")\n",
    "\n",
    "            doc = create_word_report(table_data, headers, region_filter, month_filter)\n",
    "            doc.save(\"project_report.docx\")\n",
    "            logger.info(\"Word report saved\")\n",
    "\n",
    "        else:\n",
    "            logger.warning(\"No matching issues found\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Main error: {e}\")\n",
    "        logger.exception(\"Traceback:\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d64808-27aa-43c4-a875-cc4d9cd54d2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (375863825.py, line 252)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 252\u001b[0;36m\u001b[0m\n\u001b[0;31m    severity_filter=args.severity or input(\"► Severity filter (high/medium/low, Enter for all): \")).strip().lower()\u001b[0m\n\u001b[0m                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "project_report.py\n",
    "\n",
    "Generate a Regional Issues Report from HighBond projects,\n",
    "only for projects starting on or before today, with robust\n",
    "retry, pagination, and relative-URL handling.\n",
    "Supports filtering by region, month (YYYY-MM), and issue severity.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import logging\n",
    "import re\n",
    "from datetime import datetime, date\n",
    "from collections import defaultdict\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt, RGBColor\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.enum.section import WD_ORIENT\n",
    "from docx.oxml import OxmlElement\n",
    "from docx.oxml.ns import qn\n",
    "\n",
    "# ─── Logger ───────────────────────────────────────────────────\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ─── API Constants ──────────────────────────────────────────\n",
    "API_TOKEN = \"acd6c44de072af279f19042267e98f0a70ca00c5966e118636dd87a451786347\"\n",
    "BASE_URL  = \"https://apis-eu.highbond.com/v1/orgs/48414\"\n",
    "HEADERS   = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/vnd.api+json\"\n",
    "}\n",
    "\n",
    "# ─── Session with Retry ───────────────────────────────────────\n",
    "session = requests.Session()\n",
    "retries = Retry(\n",
    "    total=5,\n",
    "    backoff_factor=1,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    "    allowed_methods=[\"GET\"]\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retries)\n",
    "session.mount(\"https://\", adapter)\n",
    "session.mount(\"http://\",  adapter)\n",
    "\n",
    "# ─── HTTP Helpers ────────────────────────────────────────────\n",
    "def get_all_projects():\n",
    "    today_str = date.today().isoformat()\n",
    "    url    = f\"{BASE_URL}/projects\"\n",
    "    page   = 1\n",
    "    params = {\n",
    "        \"filter[start_date][lte]\": today_str,\n",
    "        \"page[size]\": 100,\n",
    "        \"page[number]\": page\n",
    "    }\n",
    "\n",
    "    all_projects = []\n",
    "    while True:\n",
    "        try:\n",
    "            resp = session.get(url, headers=HEADERS, params=params, timeout=10)\n",
    "            resp.raise_for_status()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to fetch projects page {page}: {e}\")\n",
    "            break\n",
    "\n",
    "        body = resp.json()\n",
    "        batch = body.get(\"data\", [])\n",
    "        all_projects.extend(batch)\n",
    "\n",
    "        next_link = body.get(\"links\", {}).get(\"next\")\n",
    "        if not next_link:\n",
    "            break\n",
    "\n",
    "        url = urljoin(BASE_URL, next_link)\n",
    "        params = None\n",
    "        page += 1\n",
    "\n",
    "    filtered = []\n",
    "    for p in all_projects:\n",
    "        sd = p.get(\"attributes\", {}).get(\"start_date\", \"\")\n",
    "        try:\n",
    "            if datetime.strptime(sd, \"%Y-%m-%d\").date() <= date.today():\n",
    "                filtered.append(p)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    logger.info(f\"Retrieved {len(filtered)} projects up to {today_str}\")\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def get_project_issues(pid):\n",
    "    try:\n",
    "        resp = session.get(f\"{BASE_URL}/projects/{pid}/issues\", headers=HEADERS, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to fetch issues for project {pid}: {e}\")\n",
    "        return []\n",
    "    return resp.json().get(\"data\", [])\n",
    "\n",
    "# ─── HTML Cleaning & Table Extraction ────────────────────────\n",
    "def clean_html_and_extract_tables(value):\n",
    "    if not isinstance(value, str):\n",
    "        return str(value), []\n",
    "    soup = BeautifulSoup(value, \"html.parser\")\n",
    "    for tag in soup([\"script\", \"style\"]): tag.decompose()\n",
    "    for br in soup.find_all(\"br\"): br.replace_with(\"\\n\")\n",
    "\n",
    "    tables = []\n",
    "    for table in soup.find_all(\"table\"):\n",
    "        headers = [th.get_text(strip=True) for th in table.find_all(\"th\")]\n",
    "        rows    = []\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            cells = [td.get_text(strip=True) for td in tr.find_all(\"td\")]\n",
    "            if any(cells): rows.append(cells)\n",
    "        if headers or rows: tables.append((headers, rows))\n",
    "        table.decompose()\n",
    "\n",
    "    return soup.get_text().strip(), tables\n",
    "\n",
    "# ─── Column Width Calculation ─────────────────────────────────\n",
    "def _compute_column_widths(text_matrix, max_total_width_inches=10.0, min_width_inches=0.5):\n",
    "    if not text_matrix: return []\n",
    "    cols = list(zip(*text_matrix))\n",
    "    scores, total = [], 0.0\n",
    "    for col in cols:\n",
    "        lengths = [len(str(c)) for c in col]\n",
    "        mx = max(lengths)\n",
    "        has_sent = any(len(str(c).split())>5 for c in col)\n",
    "        is_num   = all(str(c).replace(\".\",\"\",1).isdigit() for c in col if c)\n",
    "        weight = 1.5 if has_sent else 0.5 if is_num else 1.0\n",
    "        scores.append(mx*weight); total+=mx*weight\n",
    "    total = total or 1.0\n",
    "    widths = [(s/total)*max_total_width_inches for s in scores]\n",
    "    widths = [max(min_width_inches,w) for w in widths]\n",
    "    used = sum(widths)\n",
    "    if used>max_total_width_inches:\n",
    "        factor = max_total_width_inches/used\n",
    "        widths = [w*factor for w in widths]\n",
    "    return [Inches(w) for w in widths]\n",
    "\n",
    "# ─── Mini-Table Insertion ────────────────────────────────────\n",
    "def add_mini_table_to_cell(cell, headers, rows):\n",
    "    header_len = len(headers) if headers else 0\n",
    "    row_lens    = [len(r) for r in rows]\n",
    "    lengths     = [header_len] + row_lens\n",
    "    col_count   = max(lengths) if lengths else 0\n",
    "\n",
    "    matrix = []\n",
    "    if headers:\n",
    "        matrix.append([headers[i] if i<header_len else \"\" for i in range(col_count)])\n",
    "    for r in rows:\n",
    "        matrix.append([r[i] if i<len(r) else \"\" for i in range(col_count)])\n",
    "\n",
    "    max_w = getattr(cell, \"width\", Inches(5)).inches\n",
    "    col_w = _compute_column_widths(matrix, max_total_width_inches=max_w)\n",
    "\n",
    "    mini = cell.add_table(rows=1 if headers else 0, cols=col_count)\n",
    "    mini.style, mini.autofit = \"Light Grid Accent 1\", False\n",
    "\n",
    "    if headers:\n",
    "        for i, txt in enumerate(matrix[0]):\n",
    "            c = mini.rows[0].cells[i]; c.width=col_w[i]\n",
    "            p = c.paragraphs[0]; r=p.add_run(txt); r.bold=True\n",
    "            p.paragraph_format.space_before=p.paragraph_format.space_after=Pt(0)\n",
    "\n",
    "    for row in matrix[1 if headers else 0:]:\n",
    "        rc = mini.add_row().cells\n",
    "        for i, txt in enumerate(row):\n",
    "            rc[i].width=col_w[i]\n",
    "            p=rc[i].paragraphs[0]; p.text=txt\n",
    "            p.paragraph_format.space_before=p.paragraph_format.space_after=Pt(0)\n",
    "            p.paragraph_format.line_spacing=1.0\n",
    "\n",
    "# ─── Page Numbers Footer ─────────────────────────────────────\n",
    "def add_global_page_numbers(doc):\n",
    "    for sec in doc.sections:\n",
    "        ftr=sec.footer; ftr.is_linked_to_previous=False\n",
    "        p=ftr.paragraphs[0]; p.alignment=WD_ALIGN_PARAGRAPH.RIGHT\n",
    "        run=p.add_run()\n",
    "        for fld_type in (\"begin\",\"separate\",\"end\"):\n",
    "            fld=OxmlElement(\"w:fldChar\"); fld.set(qn(\"w:fldCharType\"),fld_type)\n",
    "            run._r.append(fld)\n",
    "        instr=OxmlElement(\"w:instrText\"); instr.text=\"PAGE\"\n",
    "        run._r.insert(1,instr)\n",
    "        run.font.size=Pt(9); run.font.color.rgb=RGBColor(128,128,128)\n",
    "\n",
    "# ─── Build the DOCX Report ───────────────────────────────────\n",
    "def create_word_report(table_data):\n",
    "    doc = Document()\n",
    "    sec=doc.sections[0]\n",
    "    sec.orientation,sec.page_width,sec.page_height=WD_ORIENT.LANDSCAPE,Inches(11),Inches(8.5)\n",
    "    for s in doc.sections: s.top_margin=s.bottom_margin=s.left_margin=s.right_margin=Inches(0.5)\n",
    "\n",
    "    doc.styles[\"Normal\"].font.name,doc.styles[\"Normal\"].font.size=\"Calibri\",Pt(11)\n",
    "    doc.styles[\"Heading 1\"].font.size=Pt(16); doc.styles[\"Heading 1\"].font.color.rgb=RGBColor.from_string(\"107AB8\")\n",
    "    doc.styles[\"Heading 2\"].font.size=Pt(13); doc.styles[\"Heading 2\"].font.color.rgb=RGBColor.from_string(\"EF6149\")\n",
    "\n",
    "    # Cover\n",
    "    p=doc.add_paragraph(); p.alignment=WD_ALIGN_PARAGRAPH.CENTER\n",
    "    r=p.add_run(\"Regional Issues Report\\n\"); r.font.size, r.font.color.rgb=Pt(24),RGBColor.from_string(\"107AB8\")\n",
    "    doc.add_paragraph(\"Mini Group / Eleven Degrees Consulting\").alignment=WD_ALIGN_PARAGRAPH.CENTER\n",
    "    doc.add_paragraph(f\"Date: {datetime.today():%Y-%m-%d}\").alignment=WD_ALIGN_PARAGRAPH.CENTER\n",
    "    doc.add_page_break()\n",
    "\n",
    "    add_global_page_numbers(doc)\n",
    "    grouped=defaultdict(list)\n",
    "    for row in table_data: grouped[row[0]].append(row)\n",
    "    usable=Inches(10)\n",
    "\n",
    "    for pid,rows in grouped.items():\n",
    "        proj=rows[0]\n",
    "        doc.add_heading(f\"Project: {proj[1]}\",level=1)\n",
    "        hdr=doc.add_paragraph()\n",
    "        for label,idx in [(\"Branch\",2),(\"Region\",3),(\"Start Date\",4),(\"Status\",5),(\"Branch Manager\",14),(\"Operations Manager\",15),(\"Supervisor\",16)]:\n",
    "            run=hdr.add_run(f\"{label}: {proj[idx]}\\n\"); run.bold=True\n",
    "        doc.add_paragraph()\n",
    "\n",
    "        for r in rows:\n",
    "            clean_vals={}\n",
    "            for key,idx in [(\"Description\",8),(\"Implication\",9),(\"Management Comment 1\",11),(\"Management Comment 2\",12),(\"Recommendation\",13)]:\n",
    "                txt,tbls=clean_html_and_extract_tables(r[idx]); clean_vals[key]=(txt,tbls)\n",
    "            cost_val=r[10] if isinstance(r[10],(int,float)) else 0.0\n",
    "            fields=[(\"Issue Title\",(r[6],[])),(\"Severity\",(r[7],[])),(\"Description\",clean_vals[\"Description\"]),(\"Implication\",clean_vals[\"Implication\"]),(\"Cost Impact\",(f\"${cost_val:,.2f}\",[])),(\"Management Comment 1\",clean_vals[\"Management Comment 1\"]),(\"Management Comment 2\",clean_vals[\"Management Comment 2\"]),(\"Recommendation\",clean_vals[\"Recommendation\"])]\n",
    "            matrix=[[lbl,val[0]] for lbl,val in fields]; col_widths=_compute_column_widths(matrix,max_total_width_inches=usable.inches)\n",
    "            tbl=doc.add_table(rows=len(fields),cols=2); tbl.style,tbl.autofit=\"Table Grid\",False; tbl.columns[0].width,tbl.columns[1].width=col_widths\n",
    "            for i,(lbl,(txt,mini)) in enumerate(fields): left,right=tbl.rows[i].cells; left.text=lbl; left.paragraphs[0].runs[0].bold=True; right.text=txt; [add_mini_table_to_cell(right,h,rw) for h,rw in mini]\n",
    "            doc.add_paragraph()\n",
    "        doc.add_page_break()\n",
    "    return doc\n",
    "\n",
    "# ─── Entrypoint ─────────────────────────────────────────────\n",
    "def main():\n",
    "    parser=argparse.ArgumentParser(description=\"Generate Regional Issues Report from HighBond projects\")\n",
    "    parser.add_argument(\"--region\", help=\"Partial, case-insensitive filter on region\")\n",
    "    parser.add_argument(\"--month\", help=\"Start-date filter in YYYY-MM (optional)\")\n",
    "    parser.add_argument(\"--severity\", choices=[\"high\",\"medium\",\"low\"], help=\"Filter issues by severity\")\n",
    "    args,_=parser.parse_known_args()\n",
    "\n",
    "    region_filter=(args.region or input(\"► Region filter (partial, Enter to skip): \")).strip().lower()\n",
    "    month_filter=args.month or input(\"► Month filter (YYYY-MM, Enter to skip): \").strip()\n",
    "    severity_filter=args.severity or input(\"► Severity filter (high/medium/low, Enter for all): \")).strip().lower()\n",
    "\n",
    "    if month_filter:\n",
    "        try:\n",
    "            datetime.strptime(month_filter, \"%Y-%m\")\n",
    "        except ValueError:\n",
    "            logger.error(\"❌ Invalid month format. Use YYYY-MM (e.g. 2025-06).\")\n",
    "            sys.exit(1)\n",
    "    valid_sevs={\"high\",\"medium\",\"low\"}\n",
    "    if severity_filter and severity_filter not in valid_sevs:\n",
    "        logger.error(f\"❌ Invalid severity. Choose from {valid_sevs}.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    severities = {severity_filter} if severity_filter else valid_sevs\n",
    "\n",
    "    table_data=[]\n",
    "    projects=get_all_projects()\n",
    "    projects.sort(key=lambda p: p.get(\"attributes\",{}).get(\"start_date\",\"\"),reverse=True)\n",
    "\n",
    "    for pr in projects:\n",
    "        start=pr.get(\"attributes\",{}).get(\"start_date\",\"\")\n",
    "        try:\n",
    "            if datetime.strptime(start, \"%Y-%m-%d\").date()>date.today(): continue\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        pid=pr.get(\"id\"); attr=pr.get(\"attributes\",{}); name=attr.get(\"name\",\"{}\"); status=attr.get(\"status\",\"\")\n",
    "        ca=attr.get(\"custom_attributes\",[])\n",
    "        # pull and normalize\n",
    "        def normalize(v):\n",
    "            if isinstance(v,list): return \", \".join(str(x).strip() for x in v)\n",
    "            return str(v)\n",
    "        region=normalize(next((c[\"value\"] for c in ca if c.get(\"term\")==\"Region\"),[]))\n",
    "        branch=normalize(next((c[\"value\"] for c in ca if c.get(\"term\")==\"Branch\"),[]))\n",
    "        bm=normalize(next((c[\"value\"] for c in ca if c.get(\"term\")==\"Branch Manager\"),[]))\n",
    "        om=normalize(next((c[\"value\"] for c in ca if c.get(\"term\")==\"Operations Manager\"),[]))\n",
    "        sup=normalize(next((c[\"value\"] for c in ca if c.get(\"term\")==\"Supervisor\"),[]))\n",
    "\n",
    "        if region_filter and region_filter not in region.lower(): continue\n",
    "        if month_filter and not start.startswith(month_filter): continue\n",
    "\n",
    "        logger.info(f\"Fetching issues for {name!r} (Start={start}, Region={region!r})\")\n",
    "        for isd in get_project_issues(pid):\n",
    "            ia=isd.get(\"attributes\",{})\n",
    "            sev=str(ia.get(\"severity\",\"\")).lower()\n",
    "            if sev not in severities: continue\n",
    "            cm={c[\"term\"]:c[\"value\"] for c in ia.get(\"custom_attributes\",[])}\n",
    "            cost=ia.get(\"cost_impact\") if isinstance(ia.get(\"cost_impact\"),(int,float)) else 0.0\n",
    "            table_data.append([pid,name,branch,region,start,status,ia.get(\"title\",\"\"),sev.capitalize(),ia.get(\"description\",\"\"),ia.get(\"effect\",\"\"),cost,cm.get(\"Custom field 1\",\"\"),cm.get(\"Region\",\"\"),ia.get(\"recommendation\",\"\"),bm,om,sup])\n",
    "\n",
    "    if not table_data:\n",
    "        logger.warning(\"⚠️ No data matched your filters.\")\n",
    "        return\n",
    "\n",
    "    pd.DataFrame(table_data).to_csv(\"project_data.csv\",index=False)\n",
    "    safe_region=re.sub(r\"\\W+\",\"_\",region_filter or \"ALL\")\n",
    "    safe_month=re.sub(r\"\\W+\",\"_\",month_filter) if month_filter else \"ALL\"\n",
    "    fname=f\"project_report_{safe_region}_{safe_month}.docx\"\n",
    "\n",
    "    doc=create_word_report(table_data)\n",
    "    doc.save(fname)\n",
    "    logger.info(f\"✅ Report saved as {fname}\")\n",
    "\n",
    "if __name__==\"__main__\": main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04735a2a-8baf-413a-b7c9-07a0a807bc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Retrieved 280 projects up to 2025-06-24\n",
      "[INFO] Fetching issues for 'Mtondia June 2025' (Start=2025-06-17, Region='Mombasa')\n",
      "[INFO] Fetching issues for 'Majengo 1  June 2025' (Start=2025-06-10, Region='Mombasa')\n",
      "[INFO] Fetching issues for 'Bamburi 2  June 2025' (Start=2025-06-03, Region='Mombasa')\n",
      "[INFO] Fetching issues for 'Bamburi 1 June 2025' (Start=2025-06-01, Region='Mombasa')\n",
      "/tmp/ipykernel_170948/3939032138.py:289: FutureWarning: Truth-testing of elements was a source of confusion and will always return True in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  tbl_pr = tbl._tbl.tblPr or OxmlElement(\"w:tblPr\")\n",
      "[INFO] ✅ Word saved: project_report_mombasa_2025_06.docx\n",
      "[INFO] ✅ Word→PDF via LibreOffice: project_report_mombasa_2025_06.pdf\n",
      "[INFO] Start to convert project_report_mombasa_2025_06.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[WARNING] 'modified' timestamp seems very low; regarding as unix timestamp\n",
      "[WARNING] 'modified' timestamp seems very low; regarding as unix timestamp\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/8) Page 1\n",
      "[INFO] (2/8) Page 2\n",
      "[INFO] (3/8) Page 3\n",
      "[INFO] (4/8) Page 4\n",
      "[INFO] (5/8) Page 5\n",
      "[INFO] (6/8) Page 6\n",
      "[INFO] (7/8) Page 7\n",
      "[INFO] (8/8) Page 8\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/8) Page 1\n",
      "[INFO] (2/8) Page 2\n",
      "[INFO] (3/8) Page 3\n",
      "[INFO] (4/8) Page 4\n",
      "[INFO] (5/8) Page 5\n",
      "[INFO] (6/8) Page 6\n",
      "[INFO] (7/8) Page 7\n",
      "[INFO] (8/8) Page 8\n",
      "[INFO] Terminated in 3.66s.\n",
      "[INFO] ✅ PDF→DOCX: 'project_report_mombasa_2025_06_reconverted.docx'\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "project_report.py\n",
    "\n",
    "Generate a Regional Issues Report from HighBond projects,\n",
    "only for projects starting on or before today, with robust\n",
    "retry, pagination, and relative-URL handling.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import logging\n",
    "import re\n",
    "from datetime import datetime, date\n",
    "from collections import defaultdict\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "\n",
    "import re\n",
    "import subprocess\n",
    "from pdf2docx import Converter  \n",
    "\n",
    "\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt, RGBColor\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.enum.section import WD_ORIENT\n",
    "from docx.oxml import OxmlElement\n",
    "from docx.oxml.ns import qn\n",
    "from docx.enum.table import WD_ROW_HEIGHT_RULE\n",
    "from docx.enum.section import WD_SECTION\n",
    "\n",
    "\n",
    "# ─── Logger ───────────────────────────────────────────────────\n",
    "def ensure_str(val):\n",
    "    return \", \".join(val) if isinstance(val, list) else str(val or \"\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ─── API Constants ────────────────────────────────────────\n",
    "API_TOKEN = \"acd6c44de072af279f19042267e98f0a70ca00c5966e118636dd87a451786347\"\n",
    "BASE_URL  = \"https://apis-eu.highbond.com/v1/orgs/48414\"\n",
    "HEADERS   = {\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "    \"Content-Type\": \"application/vnd.api+json\"\n",
    "}\n",
    "\n",
    "# ─── Session with Retry ───────────────────────────────────────\n",
    "session = requests.Session()\n",
    "retries = Retry(\n",
    "    total=5,\n",
    "    backoff_factor=1,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    "    allowed_methods=[\"GET\"]\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retries)\n",
    "session.mount(\"https://\", adapter)\n",
    "session.mount(\"http://\",  adapter)\n",
    "\n",
    "def convert_pdf_to_docx(pdf_path: str, docx_path: str):\n",
    "    \"\"\"Convert a PDF file to DOCX using pdf2docx.\"\"\"\n",
    "    try:\n",
    "        cv = Converter(pdf_path)\n",
    "        cv.convert(docx_path, start=0, end=None)\n",
    "        cv.close()\n",
    "        logger.info(f\"✅ PDF→DOCX: '{docx_path}'\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ PDF→DOCX conversion error: {e}\")\n",
    "\n",
    "# ─── HTTP Helpers ────────────────────────────────────────────\n",
    "def get_all_projects():\n",
    "    today_str = date.today().isoformat()\n",
    "    url    = f\"{BASE_URL}/projects\"\n",
    "    page   = 1\n",
    "    params = {\n",
    "        \"filter[start_date][lte]\": today_str,\n",
    "        \"page[size]\": 100,\n",
    "        \"page[number]\": page\n",
    "    }\n",
    "    all_projects = []\n",
    "    while True:\n",
    "        try:\n",
    "            resp = session.get(url, headers=HEADERS, params=params, timeout=10)\n",
    "            resp.raise_for_status()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to fetch projects page {page}: {e}\")\n",
    "            break\n",
    "\n",
    "        body = resp.json()\n",
    "        all_projects.extend(body.get(\"data\", []))\n",
    "        next_link = body.get(\"links\", {}).get(\"next\")\n",
    "        if not next_link:\n",
    "            break\n",
    "        url = urljoin(BASE_URL, next_link)\n",
    "        params = None\n",
    "        page += 1\n",
    "\n",
    "    # filter out any that somehow slipped through with future dates\n",
    "    filtered = []\n",
    "    for p in all_projects:\n",
    "        sd = p.get(\"attributes\", {}).get(\"start_date\", \"\")\n",
    "        try:\n",
    "            if datetime.strptime(sd, \"%Y-%m-%d\").date() <= date.today():\n",
    "                filtered.append(p)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    logger.info(f\"Retrieved {len(filtered)} projects up to {today_str}\")\n",
    "    return filtered\n",
    "\n",
    "def get_project_issues(pid):\n",
    "    try:\n",
    "        resp = session.get(f\"{BASE_URL}/projects/{pid}/issues\", headers=HEADERS, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to fetch issues for project {pid}: {e}\")\n",
    "        return []\n",
    "    return resp.json().get(\"data\", [])\n",
    "\n",
    "# ─── HTML Cleaning & Table Extraction ────────────────────────\n",
    "def clean_html_and_extract_tables(value):\n",
    "    if not isinstance(value, str):\n",
    "        return str(value), []\n",
    "    soup = BeautifulSoup(value, \"html.parser\")\n",
    "    for tag in soup([\"script\", \"style\"]):\n",
    "        tag.decompose()\n",
    "    for br in soup.find_all(\"br\"):\n",
    "        br.replace_with(\"\\n\")\n",
    "\n",
    "    tables = []\n",
    "    for table in soup.find_all(\"table\"):\n",
    "        headers = [th.get_text(strip=True) for th in table.find_all(\"th\")]\n",
    "        rows    = []\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            cells = [td.get_text(strip=True) for td in tr.find_all(\"td\")]\n",
    "            if any(cells):\n",
    "                rows.append(cells)\n",
    "        if headers or rows:\n",
    "            tables.append((headers, rows))\n",
    "        table.decompose()\n",
    "\n",
    "    return soup.get_text().strip(), tables\n",
    "\n",
    "# ─── Column Width Calculation ─────────────────────────────────\n",
    "def _compute_column_widths(text_matrix, max_total_width_inches=10.0, min_width_inches=0.5):\n",
    "    if not text_matrix:\n",
    "        return []\n",
    "    cols = list(zip(*text_matrix))\n",
    "    scores, total = [], 0.0\n",
    "    for col in cols:\n",
    "        lengths = [len(str(c)) for c in col]\n",
    "        mx = max(lengths)\n",
    "        has_sent = any(len(str(c).split()) > 5 for c in col)\n",
    "        is_num   = all(str(c).replace(\".\", \"\", 1).isdigit() for c in col if c)\n",
    "        weight = 1.5 if has_sent else 0.5 if is_num else 1.0\n",
    "        scores.append(mx * weight)\n",
    "        total += mx * weight\n",
    "    total = total or 1.0\n",
    "    widths = [(s/total)*max_total_width_inches for s in scores]\n",
    "    widths = [max(min_width_inches, w) for w in widths]\n",
    "    used = sum(widths)\n",
    "    if used > max_total_width_inches:\n",
    "        factor = max_total_width_inches / used\n",
    "        widths = [w * factor for w in widths]\n",
    "    return [Inches(w) for w in widths]\n",
    "\n",
    "# ─── Mini-Table Insertion ────────────────────────────────────\n",
    "def add_mini_table_to_cell(cell, headers, rows):\n",
    "    header_len = len(headers) if headers else 0\n",
    "    row_lens = [len(r) for r in rows]\n",
    "    col_count = max([header_len] + row_lens or [0])\n",
    "    matrix = []\n",
    "    if headers:\n",
    "        matrix.append([headers[i] if i < header_len else \"\" for i in range(col_count)])\n",
    "    for r in rows:\n",
    "        matrix.append([r[i] if i < len(r) else \"\" for i in range(col_count)])\n",
    "\n",
    "    max_w = getattr(cell, \"width\", Inches(5)).inches\n",
    "    col_w = _compute_column_widths(matrix, max_total_width_inches=max_w)\n",
    "\n",
    "    mini = cell.add_table(rows=1 if headers else 0, cols=col_count)\n",
    "    mini.style, mini.autofit = \"Light Grid Accent 1\", False\n",
    "\n",
    "    if headers:\n",
    "        for i, txt in enumerate(matrix[0]):\n",
    "            c = mini.rows[0].cells[i]\n",
    "            c.width = col_w[i]\n",
    "            p = c.paragraphs[0]\n",
    "            run = p.add_run(txt); run.bold = True\n",
    "            p.paragraph_format.space_before = p.paragraph_format.space_after = Pt(0)\n",
    "\n",
    "    for row in matrix[1 if headers else 0:]:\n",
    "        rc = mini.add_row().cells\n",
    "        for i, txt in enumerate(row):\n",
    "            rc[i].width = col_w[i]\n",
    "            p = rc[i].paragraphs[0]\n",
    "            p.text = txt\n",
    "            p.paragraph_format.space_before = p.paragraph_format.space_after = Pt(0)\n",
    "            p.paragraph_format.line_spacing = 1.0\n",
    "\n",
    "# ─── Build the DOCX Report ───────────────────────────────────\n",
    "def create_word_report(table_data, region_filter):\n",
    "    doc = Document()\n",
    "\n",
    "    # ─── Setup Landscape & Margins ─────────────────────────\n",
    "    sect0 = doc.sections[0]\n",
    "    sect0.orientation = WD_ORIENT.LANDSCAPE\n",
    "    sect0.page_width, sect0.page_height = Inches(11), Inches(8.5)\n",
    "    for sect in doc.sections:\n",
    "        sect.top_margin = sect.bottom_margin = sect.left_margin = sect.right_margin = Inches(0.5)\n",
    "\n",
    "    # ─── Styles ─────────────────────────────────────────────\n",
    "    normal = doc.styles[\"Normal\"]\n",
    "    normal.font.name, normal.font.size = \"Calibri\", Pt(11)\n",
    "    h1 = doc.styles[\"Heading 1\"]\n",
    "    h1.font.name, h1.font.size, h1.font.color.rgb = \"Calibri\", Pt(16), RGBColor.from_string(\"107AB8\") \n",
    "    h2 = doc.styles[\"Heading 2\"]\n",
    "    h2.font.name, h2.font.size, h2.font.color.rgb = \"Calibri\", Pt(13), RGBColor.from_string(\"EF6149\")\n",
    "\n",
    "    # ─── Cover Page ────────────────────────────────────────\n",
    "    p = doc.add_paragraph()\n",
    "    p.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    r = p.add_run(\"Regional Issues Report\\n\")\n",
    "    r.font.size, r.font.color.rgb = Pt(24), RGBColor.from_string(\"107AB8\")\n",
    "    doc.add_paragraph(\"Mini Group / Eleven Degrees Consulting\")\\\n",
    "       .alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    doc.add_paragraph(f\"Date: {datetime.today():%Y-%m-%d}\")\\\n",
    "       .alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    doc.add_page_break()\n",
    "\n",
    "    # ─── Running Footer ────────────────────────────────────\n",
    "    for sect in doc.sections:\n",
    "        ftr = sect.footer\n",
    "        ftr.is_linked_to_previous = False\n",
    "        # clear existing paras\n",
    "        for p in list(ftr.paragraphs):\n",
    "            ftr._element.remove(p._element)\n",
    "\n",
    "        # center region text\n",
    "        p_reg = ftr.add_paragraph(f\"Regional Issues Report for “{region_filter or 'ALL'}” region\")\n",
    "        p_reg.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        p_reg.runs[0].font.name, p_reg.runs[0].font.size = \"Calibri\", Pt(9)\n",
    "\n",
    "        # right page number\n",
    "        p_pg = ftr.add_paragraph()\n",
    "        p_pg.alignment = WD_ALIGN_PARAGRAPH.RIGHT\n",
    "        run_pg = p_pg.add_run()\n",
    "        for fld in (\"begin\", \"separate\", \"end\"):\n",
    "            el = OxmlElement(\"w:fldChar\"); el.set(qn(\"w:fldCharType\"), fld)\n",
    "            run_pg._r.append(el)\n",
    "        instr = OxmlElement(\"w:instrText\"); instr.text = \"PAGE\"\n",
    "        run_pg._r.insert(1, instr)\n",
    "        run_pg.font.size, run_pg.font.color.rgb = Pt(9), RGBColor(128, 128, 128)\n",
    "\n",
    "    # ─── Group & Render Projects ───────────────────────────\n",
    "    grouped = defaultdict(list)\n",
    "    for row in table_data:\n",
    "        grouped[row[0]].append(row)\n",
    "\n",
    "    first = True\n",
    "    for pid, rows in grouped.items():\n",
    "        proj = rows[0]\n",
    "        name, branch, region, start, status = proj[1], proj[2], proj[3], proj[4], proj[5]\n",
    "        bm, om, sup = proj[14], proj[15], proj[16]\n",
    "\n",
    "        if not first:\n",
    "            section = doc.add_section(WD_SECTION.NEW_PAGE)\n",
    "        else:\n",
    "            section = doc.sections[0]\n",
    "            first = False\n",
    "\n",
    "        # ─── Header Table (2×2) ────────────────────────────\n",
    "        header = section.header\n",
    "        header.is_linked_to_previous = False\n",
    "        for p in list(header.paragraphs):\n",
    "            header._element.remove(p._element)\n",
    "\n",
    "        tbl = header.add_table(rows=2, cols=2, width=Inches(11))\n",
    "        tbl.autofit = False\n",
    "\n",
    "        # remove borders\n",
    "        tbl_pr = tbl._tbl.tblPr or OxmlElement(\"w:tblPr\")\n",
    "        if tbl._tbl.tblPr is None:\n",
    "            tbl._tbl.append(tbl_pr)\n",
    "        borders = OxmlElement(\"w:tblBorders\")\n",
    "        for edge in (\"top\", \"left\", \"bottom\", \"right\", \"insideH\", \"insideV\"):\n",
    "            b = OxmlElement(f\"w:{edge}\"); b.set(qn(\"w:val\"), \"nil\")\n",
    "            borders.append(b)\n",
    "        tbl_pr.append(borders)\n",
    "\n",
    "        # equal widths\n",
    "        tbl.columns[0].width = tbl.columns[1].width = Inches(5.5)\n",
    "\n",
    "        # ─ Logos Row ───────────────────────────────────────────\n",
    "        row0 = tbl.rows[0]\n",
    "        row0.height, row0.height_rule = Inches(2.0), WD_ROW_HEIGHT_RULE.EXACTLY\n",
    "\n",
    "        # left logo in col 0\n",
    "        cell_l = tbl.cell(0, 0)\n",
    "        cell_l.vertical_alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        tcPr = cell_l._tc.get_or_add_tcPr()\n",
    "        tcMar = OxmlElement(\"w:tcMar\")\n",
    "        left_pad = OxmlElement(\"w:left\"); left_pad.set(qn(\"w:w\"), \"200\"); left_pad.set(qn(\"w:type\"), \"dxa\")\n",
    "        tcMar.append(left_pad); tcPr.append(tcMar)\n",
    "        p_l = cell_l.paragraphs[0]; p_l.alignment = WD_ALIGN_PARAGRAPH.LEFT\n",
    "        run_l = p_l.add_run()\n",
    "        try:\n",
    "            run_l.add_picture(\"minigroup.png\", width=Inches(1.5))\n",
    "        except Exception:\n",
    "            logger.warning(\"Minigroup logo load failed\")\n",
    "\n",
    "        # right logo in col 1\n",
    "        cell_r = tbl.cell(0, 1)\n",
    "        cell_r.vertical_alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        p_r = cell_r.paragraphs[0]; p_r.alignment = WD_ALIGN_PARAGRAPH.RIGHT\n",
    "        run_r = p_r.add_run()\n",
    "        try:\n",
    "            run_r.add_picture(\"minigroup_logo.png\", width=Inches(1.5))\n",
    "        except Exception:\n",
    "            logger.warning(\"Eleven Degrees logo load failed\")\n",
    "\n",
    "        # ─ Metadata Row ───────────────────────────────────────\n",
    "        row1 = tbl.rows[1]\n",
    "        mcell = tbl.cell(1, 0).merge(tbl.cell(1, 1))\n",
    "        mcell.height, mcell.height_rule = Inches(0.5), WD_ROW_HEIGHT_RULE.EXACTLY\n",
    "        mcell.vertical_alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        p_meta = mcell.paragraphs[0]; p_meta.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        run_meta = p_meta.add_run(\n",
    "            f\"Branch: {branch}   |   Region: {region}   |   Start: {start}   |   \"\n",
    "            f\"Status: {status}   |   BM: {bm}   |   OM: {om}   |   Sup: {sup}\"\n",
    "        )\n",
    "        run_meta.font.name, run_meta.font.size = \"Calibri\", Pt(9)\n",
    "\n",
    "        # ─── Body Content ────────────────────────────────────\n",
    "        doc.add_heading(f\"Project: {name}\", level=1)\n",
    "        for k, v in {\n",
    "            \"Branch\":branch, \"Region\":region, \"Start Date\":start,\n",
    "            \"Status\":status, \"Branch Manager\":bm,\n",
    "            \"Operations Manager\":om, \"Supervisor\":sup\n",
    "        }.items():\n",
    "            p = doc.add_paragraph(); run = p.add_run(f\"{k}: \"); run.bold = True\n",
    "            p.add_run(ensure_str(v))\n",
    "        doc.add_paragraph()\n",
    "\n",
    "        # ─── Issues ─────────────────────────────────────────\n",
    "        for issue in rows:\n",
    "            desc, tables = clean_html_and_extract_tables(issue[8])\n",
    "            doc.add_heading(f\"Issue: {issue[6]}\", level=2)\n",
    "\n",
    "            fields = [\n",
    "                (\"Severity\", issue[7]), (\"Description\", desc),\n",
    "                (\"Implication\", issue[9]), (\"Cost Impact\", f\"${issue[10]:,.2f}\"),\n",
    "                (\"Mgmt Comment 1\", issue[11]), (\"Mgmt Comment 2\", issue[12]),\n",
    "                (\"Recommendation\", issue[13]),\n",
    "            ]\n",
    "            tbl_i = doc.add_table(rows=len(fields), cols=2)\n",
    "            tbl_i.style, tbl_i.autofit = \"Table Grid\", False\n",
    "            widths = _compute_column_widths(\n",
    "                [[lbl, val] for lbl, val in fields],\n",
    "                max_total_width_inches=Inches(10).inches\n",
    "            )\n",
    "            tbl_i.columns[0].width, tbl_i.columns[1].width = widths\n",
    "\n",
    "            for i, (lbl, val) in enumerate(fields):\n",
    "                c0, c1 = tbl_i.rows[i].cells\n",
    "                c0.text = lbl\n",
    "                c0.paragraphs[0].runs[0].bold = True\n",
    "                # guard None → empty string\n",
    "                c1.text = str(val) if val is not None else \"\"\n",
    "                for hdrs, rows_tbl in tables:\n",
    "                    add_mini_table_to_cell(c1, hdrs, rows_tbl)\n",
    "            doc.add_paragraph()\n",
    "\n",
    "    return doc\n",
    "\n",
    "# ─── Entrypoint ─────────────────────────────────────────────\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Generate Regional Issues Report from HighBond projects\")\n",
    "    parser.add_argument(\"--region\", help=\"Partial, case-insensitive filter on region\")\n",
    "    parser.add_argument(\"--month\",  help=\"Start-date filter in YYYY-MM (optional)\")\n",
    "    parser.add_argument(\"--severity\", help=\"Comma-separated severities to include (e.g. High,Medium,Low)\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    region_filter = (args.region or input(\"► Region filter (partial, Enter to skip): \")).strip().lower()\n",
    "    month_filter  = args.month  or input(\"► Month filter (YYYY-MM, Enter to skip): \").strip()\n",
    "    sev_input     = args.severity or input(\"► Severity filter (comma-separated, e.g. High,Medium. Enter to skip): \")\n",
    "    severity_filters = {s.strip().lower() for s in sev_input.split(\",\") if s.strip()} if sev_input else set()\n",
    "\n",
    "    if month_filter:\n",
    "        try:\n",
    "            datetime.strptime(month_filter, \"%Y-%m\")\n",
    "        except ValueError:\n",
    "            logger.error(\"❌ Invalid month format. Use YYYY-MM (e.g. 2025-06).\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    table_data = []\n",
    "    projects = get_all_projects()\n",
    "    projects.sort(key=lambda x: x.get(\"attributes\", {}).get(\"start_date\", \"\"), reverse=True)\n",
    "\n",
    "    for pr in projects:\n",
    "        start = pr[\"attributes\"].get(\"start_date\", \"\")\n",
    "        try:\n",
    "            if datetime.strptime(start, \"%Y-%m-%d\").date() > date.today():\n",
    "                continue\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        pid    = pr[\"id\"]\n",
    "        attr   = pr[\"attributes\"]\n",
    "        name   = attr.get(\"name\", \"\")\n",
    "        status = attr.get(\"status\", \"\")\n",
    "\n",
    "        ca     = attr.get(\"custom_attributes\", [])\n",
    "        region = ensure_str(next((c[\"value\"] for c in ca if c.get(\"term\")==\"Region\"), \"\"))\n",
    "        branch = ensure_str(next((c[\"value\"] for c in ca if c.get(\"term\")==\"Branch\"), \"\"))\n",
    "        bm     = ensure_str(next((c[\"value\"] for c in ca if c.get(\"term\")==\"Branch Manager\"), \"\"))\n",
    "        om     = ensure_str(next((c[\"value\"] for c in ca if c.get(\"term\")==\"Operations Manager\"), \"\"))\n",
    "        sup    = ensure_str(next((c[\"value\"] for c in ca if c.get(\"term\")==\"Supervisor\"), \"\"))\n",
    "\n",
    "        if region_filter and region_filter not in region.lower(): continue\n",
    "        if month_filter  and not start.startswith(month_filter):   continue\n",
    "\n",
    "        logger.info(f\"Fetching issues for {name!r} (Start={start}, Region={region!r})\")\n",
    "        for isd in get_project_issues(pid):\n",
    "            ia  = isd.get(\"attributes\", {})\n",
    "            sev = str(ia.get(\"severity\",\"\")).strip().lower()\n",
    "            if severity_filters and sev not in severity_filters:\n",
    "                continue\n",
    "\n",
    "            cm       = {c[\"term\"]: c[\"value\"] for c in ia.get(\"custom_attributes\",[])}\n",
    "            cost_val = ia.get(\"cost_impact\") if isinstance(ia.get(\"cost_impact\"), (int,float)) else 0.0\n",
    "\n",
    "            table_data.append([\n",
    "                pid, name, branch, region, start, status,\n",
    "                ia.get(\"title\",\"\"), sev.capitalize(),\n",
    "                ia.get(\"description\",\"\"), ia.get(\"effect\",\"\"),\n",
    "                cost_val, cm.get(\"Custom field 1\",\"\"), cm.get(\"Region\",\"\"),\n",
    "                ia.get(\"recommendation\",\"\"), bm, om, sup\n",
    "            ])\n",
    "\n",
    "    if not table_data:\n",
    "        logger.warning(\"⚠️ No data matched your filters.\"); return\n",
    "\n",
    "    pd.DataFrame(table_data).to_csv(\"project_data.csv\", index=False)\n",
    "\n",
    "    safe_region = re.sub(r\"\\W+\", \"_\", region_filter or \"ALL\")\n",
    "    safe_month  = re.sub(r\"\\W+\", \"_\", month_filter or \"ALL\")\n",
    "    base        = f\"project_report_{safe_region}_{safe_month}\"\n",
    "    docx_fname  = f\"{base}.docx\"\n",
    "    pdf_fname   = f\"{base}.pdf\"\n",
    "    recon_docx  = f\"{base}_reconverted.docx\"\n",
    "\n",
    "    # 1) Generate Word\n",
    "    doc = create_word_report(table_data, region_filter)\n",
    "    doc.save(docx_fname)\n",
    "    logger.info(f\"✅ Word saved: {docx_fname}\")\n",
    "\n",
    "    # 2) Word → PDF via LibreOffice\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\"libreoffice\", \"--headless\", \"--convert-to\", \"pdf\", docx_fname],\n",
    "            check=True\n",
    "        )\n",
    "        # LibreOffice names output \"<base>.pdf\" in fdrseawcwd\n",
    "        logger.info(f\"✅ Word→PDF via LibreOffice: {pdf_fname}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logger.error(f\"❌ LibreOffice conversion failed: {e}\")\n",
    "\n",
    "    # 3) PDF → Word via pdf2docx\n",
    "    convert_pdf_to_docx(pdf_fname, recon_docx)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec0525d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27a3808e-19a5-4a2f-b5be-b92acc156b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kitavidouglas/anaconda3/bin/python\n",
      "['/home/kitavidouglas/Desktop/DataAnalyst', '/home/kitavidouglas/anaconda3/lib/python312.zip', '/home/kitavidouglas/anaconda3/lib/python3.12'] …\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.path[:3], \"…\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
